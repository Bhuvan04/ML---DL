Create new environment with python version as 3.6.9:
  conda create --name ML_Banking_Interest python=3.6.9
  conda install -name ML_Banking_Interest python=3.6.9
  conda activate "imagescrapper"
  pip install Jupyter
  jupyter notebook

Get a list of all my environments, active environment is shown with *
  conda env list

git:
git clone https://github.com/solliancenet/udacity-intro-to-ml-labs.git

Change the path to locate the pacakage:
  import os
  import sys
  os.environ['SPARK_HOME']=r'C:\Users\bbharti\Downloads\spark-3.0.0-bin-hadoop2.7'

Mongo DB: https://code.tutsplus.com/tutorials/create-a-database-cluster-in-the-cloud-with-mongodb-atlas--cms-31840#:~:text=Fortunately%2C%20there's%20an%20easier%20alternative,in%20a%20matter%20of%20minutes.
1. Table in sql called as collection in Mongo DB
2. Rows in SQL called as records/documents in Mongo DB
3. Documents has Key Value pairs.

API --> REST --> JSON

Python --> Web Applications --> Flask (Web application development framework) --> we can build gui or just the url

While deploying we need to keep the same environment, so we have created the requirements.txt file
  pip install -r requirements.txt

Create file automatically:
  pip freeze >requirements.txt
  
Adding the web scrapping file in the pivotal:
  cf login -a https://api.run.pivotal.io
  bhuvan.pgpm18c@gmail.com
  Verma12#
  cf push

To get log:
  cf logs Youtube_reviewscrapper --recent
