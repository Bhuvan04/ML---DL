API: https://www.geeksforgeeks.org/social-network-api/

Enable personalized, real-time banking experiences with chatbots

Identify the next best action for the customer - sentiment analysis

Capture, prioritize, and route service requests to the correct employee, and improve response times - 
  A busy government organization gets innumerable service requests on an annual basis. Machine learning tools can help to capture incoming service requests, 
  to route them to the correct employee in real-time, to refine prioritization, and improve response times. 

Automate the recognition of disease
Recommend next best actions for individual care plans

Standardization rescales data so that it has a mean of 0 and a standard deviation of 1.
  The formula for this is: (ğ‘¥ âˆ’ ğœ‡)/ğœ
 
Normalization rescales the data into the range [0, 1].
  The formula for this is: (ğ‘¥ âˆ’ğ‘¥ğ‘šğ‘–ğ‘›)/(ğ‘¥ğ‘šğ‘ğ‘¥ âˆ’ğ‘¥ğ‘šğ‘–ğ‘›)
  
There are two common approaches for encoding categorical data: 
  Ordinal encoding: we simply convert the categorical data into integer codes ranging from 0 to (number of categories â€“ 1).
    One of the potential drawbacks to this approach is that it implicitly assumes an order across the categories.
  One hot encoding: we transform each categorical value into a column. If there are n categorical values, n new columns are added.
    One drawback of one-hot encoding is that it can potentially generate a very large number of columns.
 
Image Data type : The number of channels required to represent the color is known as the color depth or simply depth. With an RGB image, depth = 3, 
                  because there are three channels (Red, Green, and Blue). In contrast, a grayscale image has depth = 1, because there is only one channel.
    Encoding an Image: We need to know the following three things about an image to reproduce it:
                       Horizontal position of each pixel
                       Vertical position of each pixel
                       Color of each pixel
        Thus, we can fully encode an image numerically by using a vector with three dimensions. The size of the vector required for any given image would be the 
                        height * width * depth of that image.

Text Data Type: Text normalization is the process of transforming a piece of text into a canonical (official) form.
                1. Lemmatization is an example of normalization. A lemma is the dictionary form of a word and lemmatization is the process of reducing multiple inflections 
                to that single dictionary form. 
                2. Stop words are high-frequency words that are unnecessary (or unwanted) during the analysis, you may want to remove stop words.
                   Tokenized the text (i.e. split each string of text into a list of smaller parts or tokens)
